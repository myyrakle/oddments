"""
LangGraph 1.0ì„ ì‚¬ìš©í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì˜ˆì œ

ì´ ì˜ˆì œëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
1. Intro ì—ì´ì „íŠ¸: ì‚¬ìš©ì ì…ë ¥ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜ (HELP vs SMALLTALK)
2. Help ì—ì´ì „íŠ¸: ë„ì›€/ì§ˆë¬¸/ë¬¸ì œí•´ê²°ì´ í•„ìš”í•œ ê²½ìš° ì „ë¬¸ì ì¸ ë‹µë³€ ì œê³µ
3. Smalltalk ì—ì´ì „íŠ¸: ì¼ìƒëŒ€í™”/ì¸ì‚¬/ì¡ë‹´ì— ì¹œê·¼í•˜ê²Œ ì‘ë‹µ

LangGraph 1.0ì„ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ê°„ì˜ íë¦„ì„ ê·¸ë˜í”„ë¡œ ì •ì˜í•˜ê³ ,
ì¡°ê±´ë¶€ ë¼ìš°íŒ…ì„ í†µí•´ ì˜ë„ì— ë”°ë¼ ì ì ˆí•œ ì—ì´ì „íŠ¸ê°€ ì„ íƒë©ë‹ˆë‹¤.
"""

import os
from typing import TypedDict, Literal, Annotated
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, START, END
from langgraph.types import Command

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class State(TypedDict):
    """ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ìƒíƒœ"""
    user_input: str
    intent: Literal["HELP", "SMALLTALK", "UNKNOWN"]
    response: str
    classification_result: str


class MultiAgentSystem:
    """LangGraph ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ"""

    def __init__(self, llm):
        self.llm = llm
        self.graph = self._build_graph()
        self.app = self.graph.compile()

    def _build_graph(self) -> StateGraph:
        """LangGraph ê·¸ë˜í”„ êµ¬ì¶•"""
        graph = StateGraph(State)

        # ì—ì´ì „íŠ¸ ë…¸ë“œ ì •ì˜
        graph.add_node("intro_node", self._intro_agent)
        graph.add_node("help_node", self._help_agent)
        graph.add_node("smalltalk_node", self._smalltalk_agent)

        # ì—£ì§€ ì •ì˜ (ê·¸ë˜í”„ íë¦„)
        graph.add_edge(START, "intro_node")
        graph.add_conditional_edges(
            "intro_node",
            self._route_to_agent,
            {
                "help_node": "help_node",
                "smalltalk_node": "smalltalk_node"
            }
        )
        graph.add_edge("help_node", END)
        graph.add_edge("smalltalk_node", END)

        return graph

    def _intro_agent(self, state: State) -> State:
        """ì˜ë„ ë¶„ë¥˜ ì—ì´ì „íŠ¸"""
        print("\nğŸ¯ Intro ì—ì´ì „íŠ¸: ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„ ì¤‘...")

        intro_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

ë¶„ë¥˜ ì˜µì…˜:
- HELP: ë„ì›€ì´ë‚˜ ë¬¸ì œ í•´ê²°ì´ í•„ìš”í•œ ê²½ìš° (ì§ˆë¬¸, ê°€ì´ë“œ ìš”ì²­, íŠœí† ë¦¬ì–¼, ë¬¸ì œ í•´ê²° ë“±)
- SMALLTALK: ì¼ìƒ ëŒ€í™”ë‚˜ ì¡ë‹´ (ì¸ì‚¬, ë‚ ì”¨, ê°ì • í‘œí˜„, ê°œì¸ì  ì´ì•¼ê¸° ë“±)

ì‚¬ìš©ì ì…ë ¥: {user_input}

ì‘ë‹µ í˜•ì‹:
ë¶„ë¥˜: [HELP ë˜ëŠ” SMALLTALK]
ì´ìœ : [ë¶„ë¥˜í•œ ì´ìœ ë¥¼ í•œ ì¤„ë¡œ ì„¤ëª…]

ë¶„ë¥˜ë§Œ ëª…í™•í•˜ê²Œ í•´ì£¼ì„¸ìš”.
""")

        chain = intro_prompt | self.llm | StrOutputParser()
        result = chain.invoke({"user_input": state["user_input"]})

        # ë¶„ë¥˜ ê²°ê³¼ íŒŒì‹±
        intent = "UNKNOWN"
        if "HELP" in result.upper():
            intent = "HELP"
        elif "SMALLTALK" in result.upper():
            intent = "SMALLTALK"

        print(f"âœ… ë¶„ë¥˜ ê²°ê³¼: {intent}")

        state["intent"] = intent
        state["classification_result"] = result
        return state

    def _help_agent(self, state: State) -> State:
        """ë„ì›€ ë° ë¬¸ì œ í•´ê²° ì—ì´ì „íŠ¸"""
        print("\nğŸ’¡ Help ì—ì´ì „íŠ¸: ë¬¸ì œë¥¼ í•´ê²° ì¤‘...")

        help_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì§€ì‹ì´ í’ë¶€í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}

ë‹¤ìŒê³¼ ê°™ì´ ë„ì›€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
- ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ ì œê³µ
- í•„ìš”ì‹œ ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œê³µ
- ì¶”ê°€ ì°¸ê³ ì‚¬í•­ì´ë‚˜ íŒ í¬í•¨
- ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª… ì‚¬ìš©

ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
""")

        chain = help_prompt | self.llm | StrOutputParser()
        response = chain.invoke({"user_input": state["user_input"]})

        print(f"âœ… Help ì—ì´ì „íŠ¸ ì™„ë£Œ!")

        state["response"] = response
        return state

    def _smalltalk_agent(self, state: State) -> State:
        """ì¼ìƒ ëŒ€í™” ì—ì´ì „íŠ¸"""
        print("\nğŸ˜Š Smalltalk ì—ì´ì „íŠ¸: ì¹œê·¼í•˜ê²Œ ëŒ€í™” ì¤‘...")

        smalltalk_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê³µê°ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ëŒ€í™” ìƒëŒ€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì„¸ìš”.

ì‚¬ìš©ì ë§: {user_input}

ë‹¤ìŒê³¼ ê°™ì´ ëŒ€í™”í•´ì£¼ì„¸ìš”:
- ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ í†¤ ì‚¬ìš©
- ì ì ˆí•œ ê°ì • í‘œí˜„ê³¼ ê³µê°
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ìœ ì§€
- í•„ìš”ì‹œ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë‚˜ ì£¼ì œ í™•ì¥

í¸ì•ˆí•˜ê³  ì¦ê±°ìš´ ëŒ€í™”ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
""")

        chain = smalltalk_prompt | self.llm | StrOutputParser()
        response = chain.invoke({"user_input": state["user_input"]})

        print(f"âœ… Smalltalk ì—ì´ì „íŠ¸ ì™„ë£Œ!")

        state["response"] = response
        return state

    def _route_to_agent(self, state: State) -> Literal["help_node", "smalltalk_node"]:
        """Intro ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒ"""
        if state["intent"] == "HELP":
            return "help_node"
        elif state["intent"] == "SMALLTALK":
            return "smalltalk_node"
        else:
            return "help_node"  # ê¸°ë³¸ê°’

    def run(self, user_input: str) -> str:
        """ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        initial_state = {
            "user_input": user_input,
            "intent": "UNKNOWN",
            "response": "",
            "classification_result": ""
        }

        final_state = self.app.invoke(initial_state)
        return final_state["response"]


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”— LangGraph 1.0 ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ")
    print("=" * 60)

    # API í‚¤ í™•ì¸
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    try:
        # Gemini ëª¨ë¸ ì´ˆê¸°í™”
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.7,
            google_api_key=api_key
        )

        # ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ìƒì„±
        system = MultiAgentSystem(llm)

        print("âœ… ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\n")
        print("ğŸ’¡ ì‚¬ìš©ë²•:")
        print("- ì§ˆë¬¸ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ë©´ â†’ Help ì—ì´ì „íŠ¸ê°€ ì‘ë‹µ")
        print("- ì¸ì‚¬ë‚˜ ì¼ìƒ ëŒ€í™”ë¥¼ í•˜ë©´ â†’ Smalltalk ì—ì´ì „íŠ¸ê°€ ì‘ë‹µ")
        print("- 'quit' ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œ")
        print("\n" + "=" * 60)

        # ëŒ€í™”í˜• ë£¨í”„
        while True:
            try:
                user_input = input("\nğŸ‘¤ ë‹¹ì‹ : ").strip()

                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'ë']:
                    print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                    break

                if not user_input:
                    continue

                # ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‹¤í–‰
                print("\n" + "=" * 60)
                response = system.run(user_input)

                print("\n" + "=" * 60)
                print(f"\nğŸ¤– ì‘ë‹µ:")
                print(response)
                print("\n" + "=" * 60)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == "__main__":
    main()
